{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14: Multi-Object Photometry\n",
    "This lab will demonstrate how to use our photometry tools on an entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import scipy.stats\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import astropy.units as u\n",
    "\n",
    "# change some default plotting parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "mpl.rcParams['image.cmap'] = 'Greys_r'\n",
    "\n",
    "# run the %matplotlib magic command to enable inline plotting\n",
    "# in the current Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in our image\n",
    "hdulist = fits.open('data/aa_aql0007.fits')\n",
    "hdulist.info()\n",
    "prihdr = hdulist[0].header\n",
    "image_data = hdulist[0].data.astype(np.float) *u.adu #Ensure a good data type and units\n",
    "image_data = image_data[0:600,0:600] #Shrink our image\n",
    "print(np.median(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Useful header info\n",
    "read_noise = np.float(prihdr['rdnoise']) *u.electron\n",
    "gain = np.float(prihdr['gain']) * u.electron / u.adu\n",
    "exptime = np.float(prihdr['exptime']) * u.s\n",
    "print(read_noise)\n",
    "print(gain)\n",
    "print(exptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change into electrons\n",
    "image_data = image_data * gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also need to know the dark current.\n",
    "dark = fits.open('data/Dark.fits')\n",
    "dark_hdr = dark[0].header\n",
    "dark_data = dark[0].data *u.adu * gain\n",
    "dark_current = np.median(dark_data/(dark_hdr['exptime']*u.s))\n",
    "print(dark_current)\n",
    "dark.close() #Save some memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Detection\n",
    "The main issue with doing photometry on an entire image is finding all the sources. There are a number of ways to do this, but we will use a standard routine called DAOFIND. DAOFIND runs on images that have had their background removed. We also need to know the standard FWHM of a star in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FWHM\n",
    "We need to know what the full-width at Half Maximimum is for a generic star on our image. To do that we can extract a small image around a bright isolated star and then do some basic fitting on it. Let's pick the star located at (503,440)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data = image_data[420:460,483:523] #Don't forget to reverse x and y\n",
    "from astropy.visualization import ZScaleInterval\n",
    "interval = ZScaleInterval()\n",
    "(imin,imax) = interval.get_limits(star_data)\n",
    "plt.imshow(star_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import fit_2dgaussian\n",
    "gfit = fit_2dgaussian(star_data.value) #fit_2dgaussian can't handle quantities\n",
    "ave_sigma = np.mean([gfit.x_stddev.value,gfit.y_stddev.value])\n",
    "ave_fwhm = ave_sigma * 2.355\n",
    "print(ave_fwhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Statistics\n",
    "We are interested in the mean, median, and standard deviation of the background, but we don't really want the stars to be contributing to this. One way to solve this issue is sigma clipping. In sigma clipping we calculate a median and standard deviation and throw out data points more than some number of sigma away from the median. This process continues for some number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, median, std = sigma_clipped_stats(image_data, sigma=3.0, maxiters=5)\n",
    "print(mean,median,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOfind\n",
    "Let's run DAOFind on the whole image. Note you can change the `5` in the threshold value as appropriate for finding your targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import DAOStarFinder\n",
    "daofind = DAOStarFinder(fwhm=ave_fwhm, threshold=5.*std.value) #daofind doesn't like quantities    \n",
    "sources = daofind(image_data - median)\n",
    "sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture Photometry\n",
    "Now we just follow our procedure from Lab 13, but use apertures based on the FWHM. I have chosen 2 x FWHM for my star aperture, and 2.5 x FWHM for my sky inner annulus radius. The choice of these numbers will vary depending on your data, and it is always a balance between gettting enough star light, whicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "apertures = CircularAperture(positions, r=ave_fwhm*2)\n",
    "bkg_apertures = CircularAnnulus(positions, r_in=ave_fwhm*2.5, r_out=ave_fwhm*2.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imin,imax) = interval.get_limits(image_data)\n",
    "plt.imshow(image_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "apertures.plot(color='blue')\n",
    "bkg_apertures.plot(color='cyan', hatch='//', alpha=0.8)\n",
    "#Add some Ids\n",
    "for i, id in enumerate(sources['id']):\n",
    "    plt.annotate(id, (sources['xcentroid'][i],sources['ycentroid'][i]),color='gold')\n",
    "plt.savefig('data/apertures.png',dpi=150) #Save image as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It turns out that the best measurement of the backgroud for photometry is not the mean, but rather the mode\n",
    "def getBackground(image_data, apertures):\n",
    "    bkgs = list()\n",
    "    for m in apertures.to_mask('center'):\n",
    "        inc_pix = m.cutout(image_data)[m.cutout(image_data) *m.data >0]        \n",
    "        mode_bak = scipy.stats.mode(inc_pix)\n",
    "        bkgs.append(float(mode_bak[0]))\n",
    "    return np.array(bkgs)*u.electron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Apeture Sums\n",
    "phot = aperture_photometry(image_data, apertures)\n",
    "bphot = aperture_photometry(image_data, bkg_apertures)\n",
    "bkg_modes = getBackground(image_data,bkg_apertures)    \n",
    "bkg_sums = bkg_modes * apertures.area\n",
    "phot['bkg_sum'] = bkg_sums\n",
    "# subtract the background\n",
    "flux_bkgsub = phot['aperture_sum'] - bkg_sums\n",
    "# Any stars that have a negative flux_bkgsub are probably just background, so set it to np.nan\n",
    "flux_bkgsub[(flux_bkgsub.value < 1)] = np.nan\n",
    "phot['aperture_sum_bkgsub'] = flux_bkgsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Error\n",
    "a_b = 1 + (apertures.area/bkg_apertures.area)\n",
    "Nvariance = phot['aperture_sum_bkgsub']*u.electron + apertures.area*a_b*(\n",
    "    bkg_modes*u.electron+exptime*dark_current*u.electron + read_noise**2)\n",
    "Nsigma = np.sqrt(Nvariance)\n",
    "phot['aperture_sum_bkgsub_err'] = Nsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zpt = 25.\n",
    "mag = zpt - 2.5*np.log10(phot['aperture_sum_bkgsub'].value) + 2.5*np.log10(exptime.value)\n",
    "merr = 1.0857 *phot['aperture_sum_bkgsub_err']/phot['aperture_sum_bkgsub']\n",
    "phot['Mag'] = mag * u.mag\n",
    "phot['Mag_err'] = merr * u.mag\n",
    "phot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at your data\n",
    "Due to crowding or being near the edge of the image, some stars are probably not useful. Look at your apertures.png file to see which stars are likely not to be good.\n",
    "\n",
    "![](data/apertures.png)\n",
    "\n",
    "## Save your data\n",
    "The last step is to save your data, so that you can use it later. All of the non-image data we work with are astropy tables. You can use the `write()` method to write your data out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot.write('data/phot.csv',overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
